## 1.25周报

## 论文阅读

### CADE: Detecting and Explaining Concept Drift Samples for Security Applications

##### 概念飘移分类

1、引入新类，飘移样本来自训练集中不存在的新类。

2、类内进化，漂移样本仍然来自现有类，但他们的行为模式与训练集中的行为模式明显不同。

##### CADE的两个组件

1、检测飘移样本

实现步骤：

1、遍历类别i中的所有样本，将其降维表示

2、计算类别i的质心

3、计算类别i中每个样本与质心的距离d（欧式距离）

4、计算d的中位数

5、计算MAD（=b*（d-中位数），b为常数）

6、将测试样本降维表示

7、计算测试样本与各个类别的质心的距离D

8、计算飘移分数（=（D-每个类别的距离的中位数）/MAD），取最小的飘移分数

9、判断是否为飘移样本，将飘移分数与阈值T比较

10、输出与测试样本距离最近的样本

2、解释飘移样本

思想：引入特征扰动机制，精心选择扰动样本中的重要特征，以该重要特征替换飘移样本中的特征，观察替换后与质心的距离是否有明显减小。最后可以通过该重要特征来解释概念飘移的原因

##### 实验

使用数据集：Drebin、IDS2018

基线：

Transcend（Roberto Jordaney, Kumar Sharad, Santanu K Dash, Zhi Wang, Davide Papini, Ilia Nouretdinov, and Lorenzo Cavallaro. Transcend: Detecting concept drift in malware classification models. In Proc. of USENIX Security, 2017.）

Vanilla AE

##### 所做的实验

1、恶意软件归因，将恶意流量分类至已知家族。

用二维可视化图（T-SNE）显示分类结果

2、网络入侵检测，迭代的选择一个攻击家族作为未见过的家族。

折线图展示实验结果，横坐标为样本数，纵坐标为指标（Precision、Recall）。与基线比较，少样本也能有很好的性能。

表格，指标（Precision、Recall、F1、Norm.Effort），详细展示与基线的性能

两个箱线图，其一横坐标为使用的数据集，纵坐标为F1-Score；其二横坐标为使用的数据集，纵坐标为Normalized Invest. Efforts。举例解释该实验的目的：假设飘移样本为100，模型需检查300个样本才能达到较高的F1-Score，则Normalized Invest. Efforts=300/100。以此来展示模型的效率。

箱线图，横坐标为分类的家族，纵坐标为距离，以此来展示飘移样本与未飘移样本之间的距离。

3、漂移样本可解释性

表格，指标（比例%），表示对未知家族（作为飘移样本）中百分之多少的样本可以做出解释（即文中所说，通过添加扰动可以穿过可解释边界）

具体案例分析，以FakeDoc作为未知家族的场景，随机挑选一个飘移样本，在该样本超1000个特征中找出42个重要特征（使用解释模块），然后手动检查这些特征的语义。

4、关注类内进化的概念飘移

使用Drebin数据集（用于训练），Marvin数据集（用于测试），Marvin数据集较新。模型性能下降

解决方法：使用CADE标注出飘移样本（仅占Marvin数据集的1.7%），放入训练集，再训练

### Drift-oriented Self-evolving Encrypted Traffic  Application Classification for Actual Network  Environment（程光）

提出窗口多阈值积累测量，不断微调模型来解决概念飘移问题。

没有开源代码，但方法可以借鉴



## 下周计划

复现代码(https://github.com/whyisyoung/CADE)代码只涉及了检测概念飘移和概念漂移可解释性，没提出如何解决

找几篇以解决概念飘移问题为主的论文看看